# NLP-Preprocessing-TP1:
# L'objectif consiste à nettoyer et préparer des données textuelles pour l'analyse en effectuant les étapes suivantes :

1. Élimination de la ponctuation.
2. Tokenization (découpage du texte en mots).
3. Suppression des chiffres.
4. Suppression des mots vides.
5. Stemming (réduction des mots à leur forme racine).
6. Lemmatisation (conversion des mots en leur forme canonique).

Les résultats de chaque étape sont stockés dans un tableau pour une analyse ultérieure, facilitant la comparaison du texte original avec le texte nettoyé ( Clean-text). 


# TP2 : La vectorisation | word Embedding | Word2Vec:
## On va Essayez d'entraîner le modèle sur ce texte afin de :

1- Extraire la représentation vectorielle d'un mot 
2- Calculer la similarité entre deux mots 
3- Extraire les mots contextuels (les plus similaires) pour un mot central donné

# TP3 : NLP Classification de texte :
## Ce TP démontre le processus complet de construction d'un modèle de classification de texte en utilisant Word2Vec pour la représentation vectorielle des mots. L'utilisation de Word2Vec permet de capturer la sémantique des mots dans le modèle, ce qui peut améliorer les performances de la classification de texte.
